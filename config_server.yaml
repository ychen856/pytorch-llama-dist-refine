general:
  config_type: config_nrp.yaml
  temperature: 0.6
  top_p: 0.9
  max_seq_len: 20
  max_gen_len: 64
  max_batch_size: 4
  nsamples: 128
  Hyper_m: 5
  Lamda: 0.08
  sparsity_ratio: 0.7
  use_variant: false
  splitting_point: 21

model_config:
  attention_bias: false
  attention_dropout: 0.0
  bos_token_id: 1
  eos_token_id: 2
  hidden_act: "silu"
  hidden_size: 4096
  initializer_range: 0.02
  intermediate_size: 11008
  max_position_embeddings: 2048
  model_type: "llama"
  num_attention_heads: 32
  num_hidden_layers: 32
  num_key_value_heads: 32
  pad_token_id: 0
  pretraining_tp: 1
  rms_norm_eps: 1e-05
  rope_scaling: null
  rope_theta: 10000.0
  tie_word_embeddings: false
  torch_dtype: "float16"
  transformers_version: "4.37.2"
  use_cache: true
  vocab_size: 32000

edge_layer_setting:
  #max_layers: 10
  #start_idx: 0
  #end_idx_buff: 8
  #end_idx: 5

  max_layer_amount: 10
  max_layers: 10

  start_idx: 3
  early_idx_buff: 0
  end_idx_buff: 8
  end_idx: 5
  head_idx: 4

llama_2_7b:
  ckpt_dir: /home/ubuntu/llama-dist/llama-2-7b-sep/
  tokenizer_path: /home/ubuntu/llama-dist/llama-2-7b-sep/tokenizer.model


llama_2_7b_hf:
  ckpt_dir_hf: /home/yichun/workspace/llama-2-7b-chat-hf
  tokenizer_path_hf: /home/yichun/workspace/llama-2-7b-chat-hf


llama_2_7b_sep:
    #ckpt_dir_sep: D:/workspace/llama-2-7b-sep
    #tokenizer_path_sep: D:/workspace/llama-2-7b-sep/tokenizer.model
    ckpt_dir_sep: /home/ubuntu/llama-dist/llama-2-7b-sep/
    tokenizer_path_sep: /home/ubuntu/llama-dist/llama-2-7b-sep/tokenizer.model

llama_2_7b_hf_sep:
    ckpt_dir_hf_sep:  /home/yichun/workspace/llama-2-7b-chat-hf-sep/
    tokenizer_path_hf_sep: /home/yichun/workspace/llama-2-7b-chat-hf-sep/tokenizer.model


communication:
    server_ip: test-server-service.nrp-nautilus.io
    server_port: 80
    #client_ip: 10.147.17.35
    #client_port: 8000
    gateway_ip: 10.7.48.68
    gateway_port: 8000

